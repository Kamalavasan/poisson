//
// auto-generated by ops.py
//


#ifdef OCL_FMA
#pragma OPENCL FP_CONTRACT ON
#else
#pragma OPENCL FP_CONTRACT OFF
#endif
#pragma OPENCL EXTENSION cl_khr_fp64:enable

#include "user_types.h"
#define OPS_2D
#define OPS_API 2
#define OPS_NO_GLOBALS
#include "ops_macros.h"
#include "ops_opencl_reduction.h"

#ifndef MIN
#define MIN(a,b) ((a<b) ? (a) : (b))
#endif
#ifndef MAX
#define MAX(a,b) ((a>b) ? (a) : (b))
#endif
#ifndef SIGN
#define SIGN(a,b) ((b<0.0) ? (a*(-1)) : (a))
#endif
#define OPS_READ 0
#define OPS_WRITE 1
#define OPS_RW 2
#define OPS_INC 3
#define OPS_MIN 4
#define OPS_MAX 5
#define ZERO_float 0.0;
#define INFINITY_float INFINITY;
#define ZERO_double 0.0f;
#define INFINITY_float INFINITY;
#define ZERO_int 0;
#define INFINITY_int INFINITY;
#define ZERO_uint 0;
#define INFINITY_uint INFINITY;
#define ZERO_ll 0;
#define INFINITY_ll INFINITY;
#define ZERO_ull 0;
#define INFINITY_ull INFINITY;
#define ZERO_bool 0;



#define MAX_DIM 64
__constant int c_size = MAX_DIM;

kernel __attribute__((reqd_work_group_size(1, 1, 1)))
void ops_poisson_kernel_stencil( __global const float *in1,  // Read-Only Matrix 1
            __global const float *in2,  // Read-Only Matrix 2
           __global float *out_r,        // Output Result
           int dim) {                // Matrix Dimension. Assuming Square Matrix

    //Cyclic Partition for A as matrix multiplication needs row-wise parallel access
    float A[MAX_DIM * MAX_DIM] __attribute__((xcl_array_partition(cyclic, MAX_DIM, 1)));
    //Block Partition for B as matrix multiplication needs column-wise parallel access
    float B[MAX_DIM * MAX_DIM] __attribute__((xcl_array_partition(block, MAX_DIM, 1)));
    float C[MAX_DIM * MAX_DIM];

    //As A and B Matrix are partitioned with the factor of MAX_DIM, so to get
    // parallel row/column access, input square matrix[dimXdim] should be written
    // into local Array in MATRIX[MAX_DIM * MAX_DIM] format

    // Burst read for matrix A
    __attribute__((xcl_pipeline_loop(1)))
    __attribute__((xcl_loop_tripcount(c_size*c_size, c_size*c_size)))
    readA:
    for (int itr = 0, i = 0, j = 0; itr < dim * dim; itr++, j++) {
        if (j == dim) { j = 0; i++; }
        A[i*MAX_DIM + j] = in1[itr];
    }

    // Burst read for matrix B
    __attribute__((xcl_pipeline_loop(1)))
    __attribute__((xcl_loop_tripcount(c_size*c_size, c_size*c_size)))
    readB:
    for (int itr = 0, i = 0, j = 0; itr < dim * dim; itr++, j++) {
        if (j == dim) { j = 0; i++; }
        B[i * MAX_DIM + j] = in2[itr];
    }

    __attribute__((xcl_loop_tripcount(c_size, c_size)))
    lreorder1:
    for (int i = 0; i < dim; i++) {
        //As A and B are partition correctly so loop pipelining is applied
        // at 2nd level loop and which will eventually unroll the lower loop
        __attribute__((xcl_pipeline_loop(1)))
        __attribute__((xcl_loop_tripcount(c_size, c_size)))
        lreorder2 :
        for (int j = 0; j < dim ; j++) {
            float result = 0;
            __attribute__((xcl_loop_tripcount(c_size, c_size)))
            lreorder3:
            for (int k = 0; k < MAX_DIM; k++) {
                result += A[i * MAX_DIM +  k] * B[k * MAX_DIM + j];
            }
            C[i*MAX_DIM + j] = result;
        }
    }

    // Burst write from output matrices to global memory
    // Burst write from matrix C
    __attribute__((xcl_pipeline_loop(1)))
    __attribute__((xcl_loop_tripcount(c_size*c_size, c_size*c_size)))
    writeC:
    for (int itr = 0, i = 0, j = 0; itr < dim * dim; itr++, j++) {
        if (j == dim) { j = 0; i++; }
        out_r[itr] = C[i * MAX_DIM + j];
    }
}
